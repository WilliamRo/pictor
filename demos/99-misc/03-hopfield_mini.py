# Copyright 2022 William Ro. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ======-=======================================================-===============
r"""This script implements a minimal example of Hopfield networks and visualize
via Pictor.

The definition of the dynamics of Hopfield networks is given by

     x'(t) = -x(t) + W \cdot \Psi(x(t))
     x(0) = x_0 \in \mathbb{R}^N

where the synaptic matrix W is generated by one-shot Hebbian learning:

     W = \frac{1}{N} \sum_{\mu=1}{P} \xi^\mu \cdot \xi^{\mu T}

"""

from pictor import Pictor, Plotter

import matplotlib.pyplot as plt
import numpy as np



class HopfieldPlotter(Plotter):

  def __init__(self, pictor=None, memories=((1, 1),), x_0=(0.6, 0.2),
               T=None):
    super().__init__(self.plot, pictor)

    self.memories = memories
    self.N = 2
    self.Psi = np.tanh

    if T is None:
      self.T = np.linspace(0, 5, 501)
    else: self.T = T

    self.x_0 = None
    self.x_t_dict = {}
    self.set_x0(x_0)

    self.m = 0.2


  @property
  def P(self): return len(self.memories)

  @Plotter.property()
  def W(self):
    W = 0.
    for mu in range(self.P):
      W += np.outer(self.memories[mu], self.memories[mu])
    return W / self.N

  @property
  def xlim(self):
    x_list = [x_t[0] for x_t in self.x_t_dict.values()]
    return np.min(x_list) - self.m, np.max(x_list) + self.m

  @property
  def ylim(self):
    y_list = [x_t[1] for x_t in self.x_t_dict.values()]
    return np.min(y_list) - self.m, np.max(y_list) + self.m

  @Plotter.property()
  def landscape(self):
    # Generate energy landscape of this system

    return None


  def set_x0(self, x_0):
    x_0 = np.array(x_0).reshape((2, 1))
    self.x_0 = x_0
    self.generate_x_t_list()


  def calc_grad(self, x):
    dx = -x + np.dot(self.W, self.Psi(x))
    return dx


  def generate_x_t_list(self):
    T = self.T
    assert T[0] == 0
    self.x_t_dict = {0: self.x_0}
    x_t = self.x_0.copy()
    for i, t in enumerate(T[1:]):
      dt = T[i + 1] - T[i]

      # (1) Sync
      # dx = self.calc_grad(x_t)
      # x_t = x_t + dx * dt

      # (2) Async
      for j in range(len(x_t)):
        dx_j = self.calc_grad(x_t)[j]
        x_t[j] = x_t[j] + dx_j * dt

      # (3) Set
      self.x_t_dict[t] = x_t.copy()


  def plot(self, x, ax: plt.Axes):
    t = x
    x = self.x_t_dict[t]

    # Plot memories
    for mu in range(self.P):
      ax.plot(self.memories[mu][0], self.memories[mu][1], 'o',
              color='green')
      ax.text(self.memories[mu][0] + 0.05,
              self.memories[mu][1] + 0.05, rf'$\xi^{mu}$',
              fontsize=12, color='green')

    # Plot x_0
    ax.plot(self.x_0[0][0], self.x_0[1][0], 's', color='gray',
            label=f'$x_0$')

    # Plot x_t
    label = "$x_{" + f"{t:.2f}" + "}$"
    ax.plot(x[0], x[1], 'rs', label=label)

    m = 1.2
    ax.set_xlim([-m, m])
    ax.set_ylim([-m, m])

    ax.axvline(0, color='gray', alpha=0.2)
    ax.axhline(0, color='gray', alpha=0.2)

    ax.legend()
    ds_str = ', '.join([f'{v:.2f}' for v in self.calc_grad(x).flatten()])
    ax.set_title(f'dx = {ds_str}')



if __name__ == '__main__':
  p = Pictor()

  hp = HopfieldPlotter(memories=((1, -1),), x_0=(0.7, -0.3),
                       T=np.linspace(0, 5, 100))

  p.add_plotter(hp)

  p.objects = hp.T

  p.show()

